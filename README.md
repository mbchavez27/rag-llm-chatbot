# rag-llm-chatbot

This project is an experimental Retrieval-Augmented Generation (RAG) chatbot that combines document retrieval and large language models (LLMs) to answer questions based on context. It uses embeddings to store and search relevant information from a dataset, then integrates that context into an LLM prompt to generate more accurate and informed responses. The goal is to explore how RAG can enhance chatbot intelligence beyond simple conversation, providing a base for future development in AI-powered information retrieval and contextual chat systems.
